{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "172935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d6a4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba818ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c9dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "classes = {v: i for i, v in enumerate(sorted(os.listdir('Vehicles/')))}\n",
    "\n",
    "for root, _, files in os.walk('Vehicles/'):\n",
    "    label = os.path.basename(root)\n",
    "    if label in classes:\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
    ")\n",
    "\n",
    "for split_name, paths, split_labels in [('train', X_train, y_train), \n",
    "                                         ('test', X_test, y_test)]:\n",
    "    for path, label in zip(paths, split_labels):\n",
    "        dest_dir = os.path.join('Vehicles_split', split_name, label)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        shutil.copy2(path, os.path.join(dest_dir, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa330e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehiclesDataset:\n",
    "\n",
    "    def __init__(self, data_path: str, transforms=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.classes = {v: i for i, v in enumerate(sorted(os.listdir(data_path)))}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        for root, _, files in os.walk(data_path):\n",
    "            label = os.path.basename(root)\n",
    "            if label in self.classes:\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                        self.image_paths.append((os.path.join(root, file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, self.classes[label]\n",
    "\n",
    "    def generate_csv(self):\n",
    "        data = []\n",
    "\n",
    "        print(self.classes)\n",
    "        \n",
    "        for image_path, label in self.image_paths:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            width, height = image.size\n",
    "            \n",
    "            data.append({\n",
    "                'label': label,\n",
    "                'path': image_path,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7bac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3361eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VehiclesDataset('Vehicles/', transforms=transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()]))\n",
    "loader = DataLoader(dataset, batch_size=16, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b085f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Auto Rickshaws': 0, 'Bikes': 1, 'Cars': 2, 'Motorcycles': 3, 'Planes': 4, 'Ships': 5, 'Trains': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/PIL/Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = dataset.generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68c18676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planes</td>\n",
       "      <td>Vehicles/Planes/Plane (566).jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planes</td>\n",
       "      <td>Vehicles/Planes/Plane (450).jpg</td>\n",
       "      <td>1600</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planes</td>\n",
       "      <td>Vehicles/Planes/Plane (209).jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Planes</td>\n",
       "      <td>Vehicles/Planes/Plane (706).jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planes</td>\n",
       "      <td>Vehicles/Planes/Plane (231).jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Vehicles/Motorcycles/Motorcycle (397).png</td>\n",
       "      <td>225</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Vehicles/Motorcycles/Motorcycle (634).jpg</td>\n",
       "      <td>275</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Vehicles/Motorcycles/Motorcycle (88).jpg</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Vehicles/Motorcycles/Motorcycle (177).jpg</td>\n",
       "      <td>275</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Vehicles/Motorcycles/Motorcycle (251).jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5588 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                       path  width  height\n",
       "0          Planes            Vehicles/Planes/Plane (566).jpg    800     516\n",
       "1          Planes            Vehicles/Planes/Plane (450).jpg   1600    1200\n",
       "2          Planes            Vehicles/Planes/Plane (209).jpg   1000     541\n",
       "3          Planes            Vehicles/Planes/Plane (706).jpg    800     473\n",
       "4          Planes            Vehicles/Planes/Plane (231).jpg    800     478\n",
       "...           ...                                        ...    ...     ...\n",
       "5583  Motorcycles  Vehicles/Motorcycles/Motorcycle (397).png    225     192\n",
       "5584  Motorcycles  Vehicles/Motorcycles/Motorcycle (634).jpg    275     183\n",
       "5585  Motorcycles   Vehicles/Motorcycles/Motorcycle (88).jpg    225     225\n",
       "5586  Motorcycles  Vehicles/Motorcycles/Motorcycle (177).jpg    275     183\n",
       "5587  Motorcycles  Vehicles/Motorcycles/Motorcycle (251).jpg    100     100\n",
       "\n",
       "[5588 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da168e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/PIL/Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MEAN, STD = get_mean_and_std(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f3c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, mean: torch.Tensor, std: torch.Tensor, size: Tuple[int]) -> Tuple[DataLoader, DataLoader]: \n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    train_dataset = VehiclesDataset('Vehicles_split/train', transforms=train_transforms)\n",
    "    test_dataset = VehiclesDataset('Vehicles_split/test', transforms=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(config[\"batch_size\"]), shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=int(config[\"batch_size\"]), shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0cde6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetFive(nn.Module):\n",
    "\n",
    "    def __init__(self, classes):\n",
    "        super(LeNetFive, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            *self.make_layers(3, 6, kernel_size=5),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            *self.make_layers(6, 16, kernel_size=5),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential([\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, classes)\n",
    "        ])\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
    "        return [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e75d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, classes, dropout_prob=0.5):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            *self.make_layers(3, 96, kernel_size=11, stride=4),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            *self.make_layers(96, 256, kernel_size=5, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            *self.make_layers(256, 384, kernel_size=3, padding=1),\n",
    "            *self.make_layers(384, 384, kernel_size=3, padding=1),\n",
    "            *self.make_layers(384, 256, kernel_size=3, padding=1),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(4096, classes)\n",
    "        )\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
    "        return [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module, train_loader: DataLoader, criterion: nn.Module, optimizer: optim.Optimizer, device: torch.device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data = data.float().to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    return total_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def test_epoch(model: nn.Module, test_loader: DataLoader, criterion: nn.Module, optimizer: optim.Optimizer, device: torch.device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.float().to(device)\n",
    "            target = target.long().to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    return total_loss / len(test_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion: nn.Module, optimizer: optim.Optimizer, device: torch.device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            pred = output.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    accuracy = (all_preds == all_targets).mean()\n",
    "    precision_weighted = precision_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Recall:    {recall_weighted:.4f}\")\n",
    "    print(f\"F1-Score:  {f1_weighted:.4f}\")\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=[str(i) for i in range(conf_matrix.shape[1])],\n",
    "        y=[str(i) for i in range(conf_matrix.shape[0])],\n",
    "        colorscale='Blues',\n",
    "        text=conf_matrix,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 12},\n",
    "        colorbar=dict(title=\"Count\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Confusion Matrix',\n",
    "        xaxis_title='Predicted Label',\n",
    "        yaxis_title='True Label',\n",
    "        width=700,\n",
    "        height=700\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lenetfive(config):\n",
    "    train_loader, test_loader = load_data(config, MEAN, STD, (32, 32))\n",
    "    \n",
    "    model = LeNetFive(10)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config[\"weight_decay\"])\n",
    "    \n",
    "    epochs = config.get('epochs', 10)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_acc = test_epoch(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {test_loss:.4f}, Val Acc: {test_acc:.2f}%')\n",
    "        \n",
    "        tune.report(loss=test_loss, accuracy=test_acc, train_loss=train_loss, train_accuracy=train_acc)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=train_losses, mode='lines+markers', name='Train Loss'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=test_losses, mode='lines+markers', name='Val Loss'))\n",
    "    fig.update_layout(title='Training and Validation Loss', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "    fig.show()\n",
    "    \n",
    "    fig2 = go.Figure()\n",
    "    fig2.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=train_accs, mode='lines+markers', name='Train Acc'))\n",
    "    fig2.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=test_accs, mode='lines+markers', name='Val Acc'))\n",
    "    fig2.update_layout(title='Training and Validation Accuracy', xaxis_title='Epoch', yaxis_title='Accuracy (%)')\n",
    "    fig2.show()\n",
    "\n",
    "lenetfive_config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"epochs\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=10,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"train_loss\", \"train_accuracy\", \"training_iteration\"]\n",
    ")\n",
    "\n",
    "result = tune.run(\n",
    "    train_lenetfive,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 0.5 if torch.cuda.is_available() else 0},\n",
    "    config=lenetfive_config,\n",
    "    num_samples=20,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"lenet5_tune\"\n",
    ")\n",
    "    \n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "print(f\"\\nBest trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']:.2f}%\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb678293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_alexnet(config):\n",
    "    train_loader, test_loader = load_data(config, MEAN, STD, (227, 227))\n",
    "    \n",
    "    model = AlexNet(10)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config[\"weight_decay\"])\n",
    "    \n",
    "    epochs = config.get('epochs', 10)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_acc = test_epoch(model, test_loader, criterion, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {test_loss:.4f}, Val Acc: {test_acc:.2f}%')\n",
    "        \n",
    "        tune.report(loss=test_loss, accuracy=test_acc, train_loss=train_loss, train_accuracy=train_acc)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=train_losses, mode='lines+markers', name='Train Loss'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=test_losses, mode='lines+markers', name='Val Loss'))\n",
    "    fig.update_layout(title='Training and Validation Loss', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "    fig.show()\n",
    "    \n",
    "    fig2 = go.Figure()\n",
    "    fig2.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=train_accs, mode='lines+markers', name='Train Acc'))\n",
    "    fig2.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=test_accs, mode='lines+markers', name='Val Acc'))\n",
    "    fig2.update_layout(title='Training and Validation Accuracy', xaxis_title='Epoch', yaxis_title='Accuracy (%)')\n",
    "    fig2.show()\n",
    "\n",
    "alexnet_config = {\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-3),\n",
    "    \"epochs\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=10,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"train_loss\", \"train_accuracy\", \"training_iteration\"]\n",
    ")\n",
    "\n",
    "result = tune.run(\n",
    "    train_alexnet,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 0.5 if torch.cuda.is_available() else 0},\n",
    "    config=alexnet_config,\n",
    "    num_samples=20,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"lenet5_tune\"\n",
    ")\n",
    "    \n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "print(f\"\\nBest trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']:.2f}%\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
